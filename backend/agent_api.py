"""
Agent API - Version kh√¥ng d√πng Streamlit
D√†nh cho FastAPI Backend
"""

import os
import sys
import base64
import re
from typing import Any, Dict, List, Union

# Add parent directory to path for imports
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

from langchain_openai import ChatOpenAI
from langchain_core.messages import (
    AIMessage,
    BaseMessage,
    HumanMessage,
    SystemMessage,
    ToolMessage,
)
from langchain_core.tools import tool
from dotenv import load_dotenv
from langchain_community.tools.tavily_search import TavilySearchResults

load_dotenv(os.path.join(os.path.dirname(current_dir), ".env"))


class ToolCallingAgentRunner:
    """Minimal agent runner supporting OpenAI tool-calling for backend usage."""

    def __init__(
        self,
        llm: ChatOpenAI,
        tools: List[Any],
        system_message: str = "",
        verbose: bool = False,
    ) -> None:
        self.llm = llm
        self.llm_with_tools = llm.bind_tools(tools)
        self.tool_map = {tool.name: tool for tool in tools}
        self.system_message = system_message
        self.verbose = verbose

    def _format_history(
        self, history: Union[List[BaseMessage], None, List[Any]]
    ) -> List[BaseMessage]:
        if not history:
            return []

        formatted: List[BaseMessage] = []
        for item in history:
            if isinstance(item, BaseMessage):
                formatted.append(item)
                continue

            if isinstance(item, dict):
                role = item.get("role") or item.get("type")
                content = item.get("content", "")
                if role in ("human", "user"):
                    formatted.append(HumanMessage(content=str(content)))
                elif role in ("ai", "assistant"):
                    formatted.append(AIMessage(content=str(content)))
                elif role == "system":
                    formatted.append(SystemMessage(content=str(content)))
                elif role == "tool":
                    formatted.append(
                        ToolMessage(
                            content=str(content),
                            tool_call_id=item.get("tool_call_id", ""),
                        )
                    )
                continue

            if isinstance(item, str):
                formatted.append(HumanMessage(content=item))

        return formatted

    def invoke(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        user_input = inputs.get("input", "")
        history = self._format_history(inputs.get("chat_history"))

        messages: List[BaseMessage] = []
        if self.system_message:
            messages.append(SystemMessage(content=self.system_message))

        messages.extend(history or [])
        messages.append(HumanMessage(content=user_input))

        while True:
            response: AIMessage = self.llm_with_tools.invoke(messages)
            messages.append(response)

            tool_calls = getattr(response, "tool_calls", None) or []
            if not tool_calls:
                return {"output": response.content, "messages": messages}

            for tool_call in tool_calls:
                tool_name = getattr(tool_call, "name", None) or getattr(
                    tool_call, "tool_name", None
                )
                tool_args = getattr(tool_call, "args", None) or getattr(
                    tool_call, "arguments", None
                )
                tool_call_id = getattr(tool_call, "id", None)

                if isinstance(tool_call, dict):
                    tool_name = tool_name or tool_call.get("name")
                    tool_args = tool_args or tool_call.get("args") or tool_call.get(
                        "arguments"
                    )
                    tool_call_id = tool_call_id or tool_call.get("id") or tool_call.get(
                        "tool_call_id"
                    )

                tool_instance = self.tool_map.get(tool_name)

                if not tool_instance:
                    tool_output = f"ERROR: Tool '{tool_name}' kh√¥ng t·ªìn t·∫°i."
                else:
                    tool_params = tool_args or {}
                    if not isinstance(tool_params, dict):
                        args_schema = getattr(tool_instance, "args_schema", None)
                        if args_schema and hasattr(args_schema, "__fields__"):
                            fields = list(args_schema.__fields__.keys())
                            if len(fields) == 1:
                                tool_params = {fields[0]: tool_params}
                            else:
                                tool_params = {}
                        else:
                            tool_params = {}

                    try:
                        tool_output = tool_instance.invoke(tool_params)
                    except Exception as exc:
                        tool_output = f"ERROR: {exc}"

                if not isinstance(tool_output, str):
                    tool_output = str(tool_output)

                messages.append(
                    ToolMessage(content=tool_output, tool_call_id=tool_call_id or "")
                )

# Import tools with fallback
calculate_similarity = None
compare_skills_tool = None
process_raw_text = None

try:
    from .tools_ocr import process_raw_text  # type: ignore
except ImportError:
    try:
        from tools_ocr import process_raw_text  # type: ignore
    except ImportError as e:
        print(f"‚ö†Ô∏è tools_ocr import error: {e}")

        def process_raw_text(text):
            return text.strip() if text else ""
    else:
        print("‚úÖ tools_ocr imported")
else:
    print("‚úÖ tools_ocr imported (package relative)")

# Use OpenAI for similarity calculation
def calculate_similarity(cv_text, jd_text):
    """T√≠nh ƒëi·ªÉm ph√π h·ª£p CV-JD b·∫±ng GPT-4o"""
    try:
        llm = ChatOpenAI(model="gpt-4o", temperature=0)
        prompt = f"""B·∫°n l√† chuy√™n gia tuy·ªÉn d·ª•ng. H√£y ƒë√°nh gi√° m·ª©c ƒë·ªô ph√π h·ª£p gi·ªØa CV v√† JD sau.

CV:
{cv_text[:3000]}

JD:
{jd_text[:2000]}

H√£y CH·ªà tr·∫£ v·ªÅ M·ªòT S·ªê t·ª´ 0.0 ƒë·∫øn 1.0 (v√≠ d·ª•: 0.75) th·ªÉ hi·ªán m·ª©c ƒë·ªô ph√π h·ª£p.
- 0.0-0.3: Kh√¥ng ph√π h·ª£p
- 0.3-0.5: √çt ph√π h·ª£p
- 0.5-0.7: Ph√π h·ª£p trung b√¨nh
- 0.7-0.85: Ph√π h·ª£p t·ªët
- 0.85-1.0: R·∫•t ph√π h·ª£p

CH·ªà TR·∫¢ V·ªÄ S·ªê, KH√îNG TH√äM G√å KH√ÅC."""
        
        response = llm.invoke([HumanMessage(content=prompt)])
        score_text = response.content.strip()
        
        # Parse score
        import re
        match = re.search(r'(\d+\.?\d*)', score_text)
        if match:
            score = float(match.group(1))
            return round(min(max(score, 0.0), 1.0), 4)
        return 0.5
    except Exception as e:
        print(f"Similarity error: {e}")
        return 0.5

print("‚úÖ calculate_similarity using OpenAI GPT-4o")

try:
    from .tools_skills import compare_skills_tool  # type: ignore
except ImportError:
    try:
        from tools_skills import compare_skills_tool  # type: ignore
    except ImportError as e:
        print(f"‚ö†Ô∏è tools_skills import error: {e}")

        COMMON_SKILLS_DB = {
            "python", "java", "c++", "javascript", "typescript", "react", "angular", "vue",
            "django", "flask", "spring boot", "node.js", "tensorflow", "pytorch", "pandas",
            "numpy", "scikit-learn", "git", "docker", "kubernetes", "aws", "azure", "mysql",
            "postgresql", "mongodb", "machine learning", "deep learning", "nlp", "ai"
        }

        def compare_skills_tool(cv_text, jd_text):
            cv_lower = cv_text.lower()
            jd_lower = jd_text.lower()
            cv_skills = set()
            jd_skills = set()

            for skill in COMMON_SKILLS_DB:
                if re.search(r'\b' + re.escape(skill) + r'\b', cv_lower):
                    cv_skills.add(skill)
                if re.search(r'\b' + re.escape(skill) + r'\b', jd_lower):
                    jd_skills.add(skill)

            return {
                "cv_skills": list(cv_skills),
                "jd_skills": list(jd_skills),
                "matched_skills": list(cv_skills.intersection(jd_skills)),
                "missing_skills": list(jd_skills.difference(cv_skills))
            }
    else:
        print("‚úÖ tools_skills imported")
else:
    print("‚úÖ tools_skills imported (package relative)")

# Global storage reference (will be set by API)
_session_storage = {}

def set_session_storage(storage):
    global _session_storage
    _session_storage = storage

# ===== TOOLS =====
@tool
def tool_extract_text_from_file(file_path: str) -> str:
    """Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ file (PDF ho·∫∑c ·∫£nh)."""
    try:
        ext = file_path.lower().split('.')[-1]
        
        # Handle PDF with PyMuPDF
        if ext == 'pdf':
            try:
                import fitz  # PyMuPDF
                doc = fitz.open(file_path)
                text_output = ""
                for page in doc:
                    text_output += page.get_text() + "\n"
                doc.close()
                
                if text_output.strip():
                    return text_output.strip()
                else:
                    return "PDF kh√¥ng c√≥ text layer."
            except ImportError:
                return "ERROR: PyMuPDF ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t."
            except Exception as e:
                return f"ERROR: Kh√¥ng th·ªÉ ƒë·ªçc PDF - {str(e)}"
        
        # Handle images with GPT-4o Vision
        else:
            with open(file_path, "rb") as f:
                file_bytes = f.read()
                base64_data = base64.b64encode(file_bytes).decode('utf-8')
            
            mime_type = f"image/{ext}" if ext != 'jpg' else "image/jpeg"
            
            vision_llm = ChatOpenAI(model="gpt-4o", temperature=0)
            message = HumanMessage(
                content=[
                    {
                        "type": "text",
                        "text": "Tr√≠ch xu·∫•t TO√ÄN B·ªò vƒÉn b·∫£n trong h√¨nh ·∫£nh n√†y. Gi·ªØ nguy√™n format v√† c·∫•u tr√∫c. Ch·ªâ tr·∫£ v·ªÅ text, kh√¥ng th√™m gi·∫£i th√≠ch."
                    },
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:{mime_type};base64,{base64_data}"}
                    }
                ]
            )
            response = vision_llm.invoke([message])
            return response.content
            
    except Exception as e:
        return f"ERROR: Kh√¥ng th·ªÉ ƒë·ªçc file - {str(e)}"


@tool
def tool_process_text_input(raw_text: str) -> str:
    """L√†m s·∫°ch vƒÉn b·∫£n."""
    try:
        return process_raw_text(raw_text)
    except Exception as e:
        return f"ERROR: {str(e)}"


@tool
def tool_store_cv_text(cv_text: str) -> str:
    """L∆∞u CV text v√†o b·ªô nh·ªõ."""
    global _session_storage
    _session_storage["cv_text"] = cv_text
    return f"SUCCESS: ƒê√£ l∆∞u CV text ({len(cv_text)} k√Ω t·ª±)"


@tool
def tool_store_jd_text(jd_text: str) -> str:
    """L∆∞u JD text v√†o b·ªô nh·ªõ."""
    global _session_storage
    _session_storage["jd_text"] = jd_text
    return f"SUCCESS: ƒê√£ l∆∞u JD text ({len(jd_text)} k√Ω t·ª±)"


@tool
def tool_calculate_match_score(dummy: str = "run") -> str:
    """T√≠nh ƒëi·ªÉm ph√π h·ª£p gi·ªØa CV v√† JD."""
    global _session_storage
    cv_text = _session_storage.get("cv_text", "")
    jd_text = _session_storage.get("jd_text", "")
    
    try:
        if not cv_text or not jd_text:
            return "ERROR: Ch∆∞a c√≥ CV ho·∫∑c JD text."
        score = calculate_similarity(cv_text, jd_text)
        return str(score)
    except Exception as e:
        return f"ERROR: {str(e)}"


@tool
def tool_find_jobs_online(search_query: str) -> str:
    """T√¨m ki·∫øm vi·ªác l√†m tr√™n m·∫°ng."""
    try:
        search_tool = TavilySearchResults(max_results=5)
        results = search_tool.invoke({"query": search_query})
        
        formatted_results = ""
        for item in results:
            formatted_results += f"- Ti√™u ƒë·ªÅ: {item.get('content', 'No content')[:100]}...\n"
            formatted_results += f"  Link: {item.get('url')}\n\n"
            
        return formatted_results
    except Exception as e:
        return f"ERROR searching jobs: {str(e)}"


@tool
def tool_analyze_skills(dummy: str = "run") -> str:
    """Ph√¢n t√≠ch k·ªπ nƒÉng trong CV so v·ªõi JD."""
    global _session_storage
    cv_text = _session_storage.get("cv_text", "")
    jd_text = _session_storage.get("jd_text", "")
    
    try:
        if not cv_text or not jd_text:
            return "ERROR: Ch∆∞a c√≥ CV ho·∫∑c JD text."
        
        result = compare_skills_tool(cv_text, jd_text)
        cv_skills = ", ".join(result.get('cv_skills', []))
        missing_skills = ", ".join(result.get('missing_skills', []))
        
        return f"cv_skills: {cv_skills} ||| missing_skills: {missing_skills}"
    except Exception as e:
        return f"ERROR: {str(e)}"


@tool
def tool_suggest_jobs(dummy: str = "run") -> str:
    """G·ª£i √Ω vi·ªác l√†m ph√π h·ª£p."""
    global _session_storage
    cv_text = _session_storage.get("cv_text", "")
    
    if not cv_text:
        return "ERROR: Ch∆∞a c√≥ CV."
    
    return f"CV_CONTENT_FOR_ANALYSIS:\n{cv_text[:2000]}"


@tool
def tool_suggest_cv_improvements(dummy: str = "run") -> str:
    """ƒê·ªÅ xu·∫•t ch·ªânh s·ª≠a CV."""
    global _session_storage
    cv_text = _session_storage.get("cv_text", "")
    jd_text = _session_storage.get("jd_text", "")
    
    if not cv_text:
        return "ERROR: Ch∆∞a c√≥ CV."
    
    vision_llm = ChatOpenAI(model="gpt-4o", temperature=0.3)
    jd_context = f"\n\nJD M·ª§C TI√äU:\n{jd_text[:2000]}" if jd_text else ""
    
    prompt = f"""B·∫°n l√† chuy√™n gia t∆∞ v·∫•n CV. H√£y ph√¢n t√≠ch CV sau v√† ƒê·ªÄ XU·∫§T B·∫¢N CV M·ªöI ƒê√É ƒê∆Ø·ª¢C CH·ªàNH S·ª¨A.

CV HI·ªÜN T·∫†I:
{cv_text[:3500]}
{jd_context}

OUTPUT FORMAT:
## üìã PH√ÇN T√çCH CV HI·ªÜN T·∫†I
[ƒêi·ªÉm m·∫°nh v√† ƒëi·ªÉm y·∫øu]

## ‚úèÔ∏è ƒê·ªÄ XU·∫§T CH·ªàNH S·ª¨A
[Li·ªát k√™ c·ª• th·ªÉ nh·ªØng thay ƒë·ªïi]

## üìÑ CV M·ªöI ƒê√É CH·ªàNH S·ª¨A
```
[N·ªôi dung CV ƒë√£ ƒë∆∞·ª£c vi·∫øt l·∫°i ho√†n ch·ªânh]
```

## üí° GHI CH√ö QUAN TR·ªåNG
[L·ªùi khuy√™n th√™m]
"""
    
    try:
        response = vision_llm.invoke([HumanMessage(content=prompt)])
        return response.content
    except Exception as e:
        return f"ERROR: {str(e)}"


@tool  
def tool_analyze_cv_layout(file_path: str) -> str:
    """Ph√¢n t√≠ch layout CV t·ª´ file ·∫£nh."""
    try:
        with open(file_path, "rb") as f:
            file_bytes = f.read()
            base64_data = base64.b64encode(file_bytes).decode('utf-8')
        
        ext = file_path.lower().split('.')[-1]
        if ext == 'pdf':
            mime_type = "application/pdf"
        else:
            mime_type = f"image/{ext}" if ext != 'jpg' else "image/jpeg"
        
        vision_llm = ChatOpenAI(model="gpt-4o", temperature=0)
        
        analysis_prompt = """B·∫°n l√† chuy√™n gia ƒë√°nh gi√° CV. H√£y PH√ÇN T√çCH CHI TI·∫æT LAYOUT/B·ªê C·ª§C c·ªßa CV n√†y.

TI√äU CH√ç ƒê√ÅNH GI√Å (1-10 ƒëi·ªÉm):
1. üìê B·ªê C·ª§C T·ªîNG TH·ªÇ
2. üî§ TYPOGRAPHY
3. üé® THI·∫æT K·∫æ & M√ÄU S·∫ÆC
4. üìã C·∫§U TR√öC SECTIONS
5. üìä T√çNH CHUY√äN NGHI·ªÜP

OUTPUT FORMAT:
## üéØ ƒê√ÅNH GI√Å LAYOUT CV
### ƒêi·ªÉm T·ªïng: X/10
| Ti√™u Ch√≠ | ƒêi·ªÉm | Nh·∫≠n X√©t |
|----------|------|----------|
| ... | X/10 | ... |

### ‚úÖ ƒêI·ªÇM T·ªêT
### ‚ö†Ô∏è C·∫¶N C·∫¢I THI·ªÜN
### üí° ƒê·ªÄ XU·∫§T CH·ªàNH S·ª¨A LAYOUT
"""
        
        message = HumanMessage(
            content=[
                {"type": "text", "text": analysis_prompt},
                {"type": "image_url", "image_url": {"url": f"data:{mime_type};base64,{base64_data}"}}
            ]
        )
        
        response = vision_llm.invoke([message])
        return response.content
        
    except Exception as e:
        return f"ERROR: {str(e)}"


@tool
def tool_generate_improved_cv_image(dummy: str = "run") -> str:
    """T·∫°o m√¥ t·∫£ layout CV m·ªõi."""
    global _session_storage
    cv_text = _session_storage.get("cv_text", "")
    
    if not cv_text:
        return "ERROR: Ch∆∞a c√≥ CV."
    
    vision_llm = ChatOpenAI(model="gpt-4o", temperature=0.3)
    
    prompt = f"""D·ª±a tr√™n n·ªôi dung CV b√™n d∆∞·ªõi, h√£y t·∫°o M√î T·∫¢ CHI TI·∫æT v·ªÅ m·ªôt b·∫£n CV m·ªõi v·ªõi LAYOUT CHUY√äN NGHI·ªÜP.

N·ªòI DUNG CV:
{cv_text[:3000]}

T·∫†O M√î T·∫¢ VISUAL LAYOUT M·ªöI:
## üñºÔ∏è M√î T·∫¢ LAYOUT CV M·ªöI
### C·∫•u tr√∫c t·ªïng th·ªÉ
### Header Section
### Main Sections
### Color Scheme
### Typography Guide
### Visual Elements
## üìù N·ªòI DUNG CV ƒê√É T·ªêI ∆ØU
## üîó TEMPLATE G·ª¢I √ù
"""
    
    try:
        response = vision_llm.invoke([HumanMessage(content=prompt)])
        return response.content
    except Exception as e:
        return f"ERROR: {str(e)}"


def initialize_agent_api(verbose: bool = False) -> ToolCallingAgentRunner:
    """Kh·ªüi t·∫°o Agent cho API."""
    llm = ChatOpenAI(model="gpt-4o", temperature=0)

    tools = [
        tool_extract_text_from_file,
        tool_process_text_input,
        tool_store_cv_text,
        tool_store_jd_text,
        tool_calculate_match_score,
        tool_analyze_skills,
        tool_suggest_jobs,
        tool_find_jobs_online,
        tool_suggest_cv_improvements,
        tool_analyze_cv_layout,
        tool_generate_improved_cv_image,
    ]

    system_message = (
        "B·∫°n l√† AI Recruitment Expert chuy√™n nghi·ªáp.\n\n"
        "NHI·ªÜM V·ª§:\n"
        "- Ph√¢n t√≠ch CV/JD, t√≠nh ƒëi·ªÉm, so s√°nh k·ªπ nƒÉng.\n"
        "- G·ª£i √Ω vi·ªác l√†m v√† ƒë√°nh gi√° tr·∫°ng th√°i ph·ªèng v·∫•n.\n"
        "- ƒê·ªÅ xu·∫•t ch·ªânh s·ª≠a CV b·∫±ng ti·∫øng Anh.\n"
        "- Ph√¢n t√≠ch layout CV khi ƒë∆∞·ª£c y√™u c·∫ßu.\n\n"
        "QUAN TR·ªåNG:\n"
        "- V·ªõi file: D√πng tool_extract_text_from_file.\n"
        "- Lu√¥n l∆∞u CV/JD sau khi tr√≠ch xu·∫•t.\n"
        "- Tr·∫£ l·ªùi r√µ r√†ng, d·ªÖ ƒë·ªçc."
    )

    return ToolCallingAgentRunner(
        llm=llm,
        tools=tools,
        system_message=system_message,
        verbose=verbose,
    )


# ===== API FUNCTIONS =====

def analyze_cv_jd_api(cv_input: str, jd_input: str, cv_type: str, jd_type: str, storage: dict) -> str:
    """API version of analyze_cv_jd"""
    global _session_storage
    _session_storage = storage
    
    agent = initialize_agent_api()
    
    user_query = f"""
Th·ª±c hi·ªán ph√¢n t√≠ch CV-JD:

TH√îNG TIN:
- CV: type={cv_type}, data={cv_input[:150]}...
- JD: type={jd_type}, data={jd_input[:150]}...

B∆Ø·ªöC 1: TR√çCH XU·∫§T CV TEXT
N·∫øu cv_type == 'file': G·ªçi tool_extract_text_from_file("{cv_input}")
N·∫øu cv_type == 'text': G·ªçi tool_process_text_input v·ªõi n·ªôi dung CV
SAU ƒê√ì: G·ªçi tool_store_cv_text v·ªõi k·∫øt qu·∫£

B∆Ø·ªöC 2: TR√çCH XU·∫§T JD TEXT
L√†m t∆∞∆°ng t·ª± v·ªõi JD, SAU ƒê√ì: G·ªçi tool_store_jd_text

B∆Ø·ªöC 3: T√çNH ƒêI·ªÇM PH√ô H·ª¢P
G·ªçi: tool_calculate_match_score("run")

B∆Ø·ªöC 4: PH√ÇN T√çCH K·ª∏ NƒÇNG
G·ªçi: tool_analyze_skills("run")

B∆Ø·ªöC 5: G·ª¢I √ù KH√ìA H·ªåC
D·ª±a v√†o missing_skills, ƒë·ªÅ xu·∫•t 3-5 kh√≥a h·ªçc t·ª´ Coursera, Udemy, edX.

B∆Ø·ªöC 6: VI·∫æT B√ÅO C√ÅO
# üìä K·∫æT QU·∫¢ PH√ÇN T√çCH
## üéØ ƒêi·ªÉm Ph√π H·ª£p: [SCORE]
## ‚úÖ K·ªπ NƒÉng ƒê√£ C√≥
## ‚ö†Ô∏è K·ªπ NƒÉng C·∫ßn B·ªï Sung
## üìö Kh√≥a H·ªçc ƒê·ªÅ Xu·∫•t
## üí° Nh·∫≠n X√©t
"""
    
    try:
        result = agent.invoke({"input": user_query, "chat_history": []})
        return result['output']
    except Exception as e:
        return f"‚ùå L·ªói: {str(e)}"


def find_suitable_jobs_api(storage: dict) -> str:
    """API version of find_suitable_jobs"""
    global _session_storage
    _session_storage = storage
    
    cv_content = storage.get("cv_text", "")
    jd_content = storage.get("jd_text", "")
    
    if not cv_content:
        return "‚ùå Ch∆∞a c√≥ d·ªØ li·ªáu CV. Vui l√≤ng ph√¢n t√≠ch CV tr∆∞·ªõc!"
    
    agent = initialize_agent_api()
    
    jd_context = f"\nJD ƒê√É PH√ÇN T√çCH:\n{jd_content[:2000]}" if jd_content else ""
    
    query = f"""
D·ª±a v√†o CV b√™n d∆∞·ªõi, th·ª±c hi·ªán:
1. Ph√¢n t√≠ch h·ªì s∆°
2. S·ª≠ d·ª•ng tool_find_jobs_online ƒë·ªÉ t√¨m 5+ c√¥ng vi·ªác ƒëang tuy·ªÉn
3. ƒê√°nh gi√° TR·∫†NG TH√ÅI PH·ªéNG V·∫§N cho m·ªói v·ªã tr√≠

N·ªòI DUNG CV:
{cv_content[:4000]}
{jd_context}

Y√äU C·∫¶U OUTPUT:
# üíº G·ª¢I √ù VI·ªÜC L√ÄM

## üîç Ph√¢n T√≠ch Nhanh
## üéØ ƒê√ÅNH GI√Å KH·∫¢ NƒÇNG PH·ªéNG V·∫§N
- **Kh·∫£ nƒÉng ƒë∆∞·ª£c g·ªçi ph·ªèng v·∫•n:** [Cao/Trung b√¨nh/Th·∫•p]
- **ƒêi·ªÉm m·∫°nh khi ph·ªèng v·∫•n:**
- **C·∫ßn chu·∫©n b·ªã th√™m:**

## üåê C√°c C√¥ng Vi·ªác ƒêang Tuy·ªÉn
### 1. [T√™n V·ªã Tr√≠] - [C√¥ng Ty]
   - üîó **Link:**
   - üìä **M·ª©c ƒë·ªô ph√π h·ª£p:**
   - üìû **TR·∫†NG TH√ÅI PH·ªéNG V·∫§N:** üü¢/üü°/üî¥

## üìã T·ªîNG K·∫æT TR·∫†NG TH√ÅI ·ª®NG TUY·ªÇN
| V·ªã Tr√≠ | C√¥ng Ty | Kh·∫£ NƒÉng PV | ∆Øu Ti√™n |
|--------|---------|-------------|---------|

## üí° L·ªúI KHUY√äN CHU·∫®N B·ªä PH·ªéNG V·∫§N
"""
    
    try:
        result = agent.invoke({"input": query, "chat_history": []})
        return result['output']
    except Exception as e:
        return f"‚ùå L·ªói: {str(e)}"


def chat_with_agent_api(user_message: str, storage: dict) -> str:
    """API version of chat_with_agent"""
    global _session_storage
    _session_storage = storage
    
    agent = initialize_agent_api()
    
    cv_text = storage.get("cv_text", "")
    jd_text = storage.get("jd_text", "")
    chat_history = storage.get("chat_history", [])

    context_data = ""
    if cv_text:
        context_data += f"\n=== N·ªòI DUNG CV ===\n{cv_text[:3000]}\n"
    if jd_text:
        context_data += f"\n=== N·ªòI DUNG JD ===\n{jd_text[:3000]}\n"

    history_text = "\n".join(chat_history[-6:])

    full_query = f"""
TH√îNG TIN NG·ªÆ C·∫¢NH:
{context_data}

L·ªäCH S·ª¨ TR√í CHUY·ªÜN:
{history_text}

C√ÇU H·ªéI M·ªöI:
{user_message}
"""

    try:
        result = agent.invoke({"input": full_query, "chat_history": []})
        output_text = result['output']
        
        # Save to history
        storage["chat_history"].append(f"User: {user_message}")
        storage["chat_history"].append(f"AI: {output_text}")
        
        return output_text
    except Exception as e:
        return f"‚ùå L·ªói: {str(e)}"


def suggest_cv_improvements_api(storage: dict) -> dict:
    """API version of suggest_cv_improvements"""
    global _session_storage
    _session_storage = storage
    
    if not storage.get("cv_text"):
        return {"success": False, "output": "‚ùå Ch∆∞a c√≥ CV. Vui l√≤ng ph√¢n t√≠ch CV tr∆∞·ªõc!"}
    
    agent = initialize_agent_api()
    
    try:
        result = agent.invoke(
            {
                "input": (
                    "Please call tool_suggest_cv_improvements and deliver the rewritten CV entirely in English. "
                    "Do not include Vietnamese explanations."
                ),
                "chat_history": [],
            }
        )
        output_text = result["output"]
        response_payload = {"success": True, "output": output_text}

        return response_payload
    except Exception as e:
        return {"success": False, "output": f"‚ùå L·ªói: {str(e)}"}


def analyze_cv_layout_api(file_path: str) -> str:
    """API version of analyze_cv_layout"""
    agent = initialize_agent_api()
    
    try:
        result = agent.invoke({
            "input": f"H√£y s·ª≠ d·ª•ng tool_analyze_cv_layout v·ªõi file '{file_path}' ƒë·ªÉ ph√¢n t√≠ch layout CV.",
            "chat_history": []
        })
        return result['output']
    except Exception as e:
        return f"‚ùå L·ªói: {str(e)}"


def generate_improved_cv_api(storage: dict) -> str:
    """API version of generate_improved_cv"""
    global _session_storage
    _session_storage = storage
    
    if not storage.get("cv_text"):
        return "‚ùå Ch∆∞a c√≥ CV. Vui l√≤ng ph√¢n t√≠ch CV tr∆∞·ªõc!"
    
    agent = initialize_agent_api()
    
    try:
        result = agent.invoke({
            "input": "H√£y s·ª≠ d·ª•ng tool_generate_improved_cv_image ƒë·ªÉ t·∫°o m√¥ t·∫£ layout CV m·ªõi.",
            "chat_history": []
        })
        return result['output']
    except Exception as e:
        return f"‚ùå L·ªói: {str(e)}"

